••• R14.22 Develop an O(n log(n)) algorithm for removing duplicates from an array if the
resulting array must have the same ordering as the original array. When a value
occurs multiple times, all but its first occurrence should be removed.

my first instinct is to use something similar to merge sort but which doesn't sort the items, rather removes duplicates. I already updated the merge sort algo to remove duplicates, so this shouldn't be too hard.

inputs:
a=[1,1,1,3,2,4,4,2,5,3]
desired outputs:
a=[1,3,2,4,5,0,0,0,0,0] usedCapacity = 5

solving by hand:
intuitively i solve the remove duplicates problem by looking at each element then looking at every following element and removing it if it's the same.
But that would be an n**2 efficiency algorithm, so it won't do.

I could try using recursion. if i break the array down into one element arrays by continuously dividing it in two. i know that single element arrays don't have duplciates. and then i can rebuild the original array by combining the one element arrays but removing duplicates in the process. this works naturally if the duplicates are next to each other. but what if not? i remove duplciates each merge step. so you might have two 3 element arrays, like [1,3,2] and [1,2,5] that needs to to be merged to preserve order and remove duplciates. they aren't ordered so that will require n operations for each element to check it isn't in the second array, and that will be repeated for each elements, so on the smaller level there are n**2 operations happening. not sure how to calculate the total big oh efficiency here. maybe I should write it out in pseudcode and just try after that.
 
```
array = [1, 8, 8, 8, 2, 4, 9, 9, 2, 9, 3]
usedCapacity = array.length
int withoutDuplicatesCapacity = removeDuplicates(array)

/** removes duplicates from array and returns used capacity **/
int removeDuplicates(array)                     // executes log(n) times and each time does n + n**2 + n operations, so O(log(n) * n**2)

    if array.length == 0
        return 0
    if array.length == 1 
        return 1
    
    firstHalf = [array.length/2]
    secondHalf = [array.length - firstHalf.length]
    i = 0
    while i < firstHalf.length
        firstHalf[i] = array[i]
        i++
    while i < array.length
        secondHalf[i] = array[i]
        i++                                 // n operations to fill halves

    mergeWithoutDuplicates(removeDuplicates(firstHalf), removeDuplicates(secondHalf), array)      // circa n**2 operations
    return array.length

/** merges first and second array into single array without elements from second array that are already present in first array, 
    and maintains ordering of elements from beginning of first array to end of second array **/
int[] mergeWithoutDuplicates(firstHalf, secondHalf, mergedArray)                 // O(n**2)
{
    uniqueList = []
    for (i = 0, i < firstHalf.length, i++)                  // O(n)
        uniqueList.add(firstHalf[i]) // firstHalf items are guaranteed to be unqiue cause merged starting from length 1 upwards
    for (i = 0, i < secondHalf.length, i++)                 // O(n**2)
        if (!contains(uniqueList, secondHalf[i]))           // O(n)
            uniqueList.add(secondHalf[i])
    
    mergedArray = uniqueList.length
    for (i = 0, i < uniqueList.length, i++)             // if all elements unique then uniqueList is first length + second length, so O(n)
        merged[i] = uniqueList.get(i)

    return merged
}

bool contains(list, item)                       // O(n)
    for (i = 0, i < list.length, i++)
        if list[i] == item
            return true
    return false

```

damn, my merge sort inspired algorithm for removing duplicates has O(n**2 * log(n)) efficiency, so it's less efficient than desires O(n log(n)) efficiency desired. The different between my algo and merge sort is that when merging the two sorted half of the array in merge sort it's an O(n) operation because it just adds elements to the merged array comparing them, which is an O(n) operation, but what I'm doing is linear searching the first array for each element of the second array to check it's not a duplicate, which is an O(n squared) operation.

Another alternative I thought of is thinking of this recursively. simplify input by removing an element. and get the simplified input's solution, i.e. without duplicates, and then combine the remove element by iterating over the solution for the simplified input. That combination step is an O(n) operation, and it repeats n times, so this is still an O(n**2) duplicate removal algorithm.

Ah, it hit me. how obivous.
I can make a copy of the array to remove duplicates from. That's circa n operations.
Then I can sort the copy of the array with merge sort, that's circa n log(n) operations.
Then I can count how often elements occur in the sorted list by iterating over values and incrementing a count of how long the run is as I do so, if a value is differernt from the previous one, then I can add the previous count to an array of counts before resetting it to zero
hmmm, the problem now is that while i have counts for each value, I need to find a way to iterate of the first array and check if a value should be removed, but it's hard to do so because it's in a different order to the items in the sorted array we counted the values of, so the positions of counts in the counts array will have no way of being associated with items in the original array.

hmmm, what if i stick to the merge sort thing I did earlier but instead of checking if something is a duplicate with an O(n) algo I instead add the individual items (the 1 element lists) to a sorted array list of unique items. that way, when merging list, i can perform a binary search which is circa log(n) operations, to check if an item already exists before in the list, and that way it's n log(n) to check if an item being merged into a bigger list is a duplicate. yeah, that should work, problem solved. let me try and edit the pseudocode from before...

```
array = [1, 8, 8, 8, 2, 4, 9, 9, 2, 9, 3]
usedCapacity = array.length
int withoutDuplicatesCapacity = removeDuplicates(array)

sortedUniqueItems = new ArrayList()

int binarySearch(item, ascendingSortedList)
    binarySearch(item, ascendingSortedList, 0, ascendingSortedList.length - 1)

/** returns the index of an item in a list by searching for the item with binary search, or the negative val of the index it would belong if not found **/
int binarySearch(item, ascendingSortedList, from, to)    // n + (2 * (n**2 log(n))) + n**2 log(n) operations, so O(n**2 log(n)) efficiency
    searchDistance = to - from + 1
    if searchDistance < 1
        return - from
    middleIndex = from + searchDistance / 2
    if ascendingSortedList[middleIndex] == item
        return middleIndex
    else if ascendingSortedList[middleIndex] > item
        return binarySearch(item, ascendingSortedList, from, middleIndex - 1)
    else if ascendingSortedList[middleIndex] < item
        return binarySearch(item, ascendingSortedList, middleIndex + 1, to)

/** removes duplicates from array and returns used capacity **/
int removeDuplicates(array)

    if array.length == 0
        return 0
    if array.length == 1
        uniqueItemsPos = binarySearch(array[0], sortedUniqueItems)
        if uniqueItemsPos >= 0
            sortedUniqueItems.add(uniqueItemsPos, array[0])
        return 1
    
    firstHalf = [array.length/2]
    secondHalf = [array.length - firstHalf.length]
    i = 0
    while i < firstHalf.length
        firstHalf[i] = array[i]
        i++
    while i < array.length
        secondHalf[i] = array[i]
        i++                              
                                                // n operations to fill array halves

    removeDuplicates(firstHalf)                 // removeDuplicates operations / 2, so n + mergeDuplicatesOperations, n + n**2 * log(n), O(n**2 log(n))
    removeDuplicates(secondHalf)                // removeDuplicates operations / 2, so n + mergeDuplicatesOperations
                                                // 2 * (n**2 log(n)) operations 

    mergeWithoutDuplicates(firstHalf, secondHalf, array)            // n**2 * log(n) operations
    return array.length

/** merges first and second array into single array without elements from second array that are already present in the array being built, 
    and maintains ordering of elements from beginning of first array to end of second array **/
int[] mergeWithoutDuplicates(firstHalf, secondHalf, mergedArray)        // n**2 log(n) operations              
{
    uniqueList = []
    for (i = 0, i < firstHalf.length, i++)        
        posInMerged = binarySearch(firstHalf[i], sortedUniqueItems)         // log n operations
        if (posInMerged >= 0)         
            uniqueList.add(posInMerged, firstHalf[i])       // n ops for shift of items in array list!
    for (i = 0, i < secondHalf.length, i++)        
        posInMerged = binarySearch(secondHalf[i], sortedUniqueItems)        // log n operations
        if (posInMerged >= 0)         
            uniqueList.add(posInMerged, secondHalf[i])     // n operations for shifting array items in array list!
                                                                        // n**2 * log n operations
    merged = uniqueList.length
    for (i = 0, i < uniqueList.length, i++)             
        merged[i] = uniqueList.get(i)

    return merged
}
```

ahhhhh, the arraylist adding at a certain index and shifting elements to the right is an O(n) operation, so it's making my algo n**2 log(n) efficiency.
i need to find a more efficient way of adding items to the sorted list of unique items

okay, what if i stop trying to edit merge sort and go back to the other idea.

I make a copy of the array. O(n)
I sort the copy with merge sort O(n log(n))
I make a sorted list of unique items in the original array by removing duplicates from the copied list which is now sorted, which is O(n) if I only iterate over each element once, and more efficient than doing so for an unsorted list which would require linear searching the whole list for each item O(n)
I make a solution array by iterating over items in the original array and binary searching the list of unique items O(n log(n)) to see if an item needs to be added to the solution array, but i'm not sure how to stop the item from being searched for again to avoid duplicates, removal for example would require O(n) shifting, which would be n*n efficiency when done for each item in the original array.

hmmmm, what if i made a class which wrapped a value and associated a boolean _seen_ flag with it, I can create it with ~n operations by iterating over the unique items array, and creating wrappers with seen set to false for each one.
then for each item in the original array I binary search the sortedWrappedUniqueItems array and if the seen value is false, I add it to the solution array, but if it has been seen already I don't.
And then at the very end I copy the solution values into the original array, and return the used capacity, i.e. the length of the solution values array.

Yeah, that should work:
```
class WrappedItem
    int value
    boolean seen

int removeDuplicates(int[] array)           // O(n log(n)) is roughly the num of operations the algo performs relative to input size n
    int originalLength = array.length
    if originalLength == 0
        return 0

    // Step 1: Copy the input array                 // n operations
    int[] copiedArray = new int[originalLength]
    int currentIndex = 0
    while currentIndex < originalLength
        copiedArray[currentIndex] = array[currentIndex]
        currentIndex++

    // Step 2: Sort the copied array                // n log(n) operations
    mergeSort(copiedArray, 0, originalLength - 1)

    // Step 3: Create sorted unique list of WrappedItems            // n operations
    WrappedItem[] sortedUniqueWrappedItems = new WrappedItem[originalLength]
    int uniqueItemCount = 0

    sortedUniqueWrappedItems[0] = new WrappedItem()
    sortedUniqueWrappedItems[0].value = copiedArray[0]
    sortedUniqueWrappedItems[0].seen = false
    uniqueItemCount++

    currentIndex = 1
    while currentIndex < originalLength
        if copiedArray[currentIndex] != copiedArray[currentIndex - 1]
            sortedUniqueWrappedItems[uniqueItemCount] = new WrappedItem()
            sortedUniqueWrappedItems[uniqueItemCount].value = copiedArray[currentIndex]
            sortedUniqueWrappedItems[uniqueItemCount].seen = false
            uniqueItemCount++
        currentIndex++

    // Step 4: Iterate over original array and fill result                  // n log(n) operations
    int writePosition = 0
    currentIndex = 0
    while currentIndex < originalLength
        int matchIndex = binarySearch(sortedUniqueWrappedItems, 0, uniqueItemCount - 1, array[currentIndex])            // log n operations
        if matchIndex >= 0 and sortedUniqueWrappedItems[matchIndex].seen == false
            array[writePosition] = array[currentIndex]
            sortedUniqueWrappedItems[matchIndex].seen = true
            writePosition++
        currentIndex++

    // Step 5: Clear remaining elements in array       // n operations
    while writePosition < originalLength
        array[writePosition] = 0
        writePosition++

    return writePosition

int binarySearch(WrappedItem[] list, int fromIndex, int toIndex, int targetValue)       // log n operations
    while fromIndex <= toIndex
        int midIndex = fromIndex + (toIndex - fromIndex) / 2
        if list[midIndex].value == targetValue
            return midIndex
        else if list[midIndex].value > targetValue
            toIndex = midIndex - 1
        else
            fromIndex = midIndex + 1
    return -1

```
