### •• R14.27 

A stable sort does not change the order of elements with the same value. This is a
desirable feature in many applications. 

Consider a sequence of e-mail messages. If you sort by date and then by sender, you’d like the second sort to preserve the rela-
tive order of the first, so that you can see all messages from the same sender in date
order. Is selection sort stable? Insertion sort? Why or why not?

### Is selection sort stable? Insertion sort? Why or why not? 

So, stable sort is a sorting algorithm which preserves the original ordering of items with the same value in the array being sorted. For example, if I sort some emails by date and then by sender, I would like the sorting algorithm which sorts by sender to be stable so that the emails sorted by sender are also ordered by date for every given sender. Because maintaining the previous ordering of items by a certain measure is desirable when sorting items by another measure, stable sorting algorithms are desirable.

#### Is selection sort stable? Why or why not?
To see if selection sort is stable, let me walk through what happens when we sort an array of values with duplicates using selection sort.
e.g. [2(a),3(a),3(b),2(b),2(c)]
I've used letters to label the duplicate values so I can tell them apart.
selection sort would do:
// 1st iteration over n items when sorted past of array is empty
// selects the smallest element in the unsorted tail region (whole array for first iteration) and moves it to the front by swapping it with the front element, no swaps this iteration because smallest item is already at the front
[2(a)][3(a),3(b),2(b),2(c)]
//2nd iter, selects the item in the smallest position in the tail and moves it to the front by swapping it with the front element, notice how this changes the ordering of 3(b) and 3(a) so that they are now in a different order compared to the order they were in in the original array
[2(a), 2(b)][3(b),3(a),2(c)]
// 3rd iter, swaps 2(c) with 3(b)
[2(a), 2(b), 2(c)][3(a), 3(b)]
// 4th iter, swaps 3(a) with itself
[2(a), 2(b), 2(c), 3(a)][3(b)]
// 5th iter, tail already sorted so stays the same
[2(a), 2(b), 2(c), 3(a), 3(b)]

Okay, interesting, so the result of our selection sort example was a stable sort, but I noticed that at some point the order of items was unstable, i.e. different from their original ordering, and it was a stroke of luck that there was a third value _2_ which caused the _3_**b** to be swapped with it and regain its origal positioning relative to _3_**a**. 
Had the array only had 4 elements, the selection sort would have been unstable:
e.g. [2(a),3(a),3(b),2(b)]
// 1st iter [2(a)][3(a), 3(b), 2(b)]
// 2nd iter [2(a), 2(b)][3(b), 3(a)]
// 3rd iter [2(a), 2(b), 3(b)][3(a)]
// 4th iter [2(a), 2(b), 3(b), 3(a)]

So, selection sort is unstable, because it swaps the smallest element from the unsorted tail of the array with the first element in the unsorted tail, which becomes the last element in the sorted head. And by performing a swapping of elements the selection sort algorithm changes the ordering of items in the original array, moving duplicate values that were once preceeding their respective duplicate to the end of the array, and sometimes not swapping their originally posterior duplicate back to a posterior position. This leads to an unstable sorting of items where the ordering of identical values in the original array is not maintained in the sorted array.
If instead of swapping next item to add to the head of the sorted part of the array with the item at the start of the tail of the unsorted part of the array, the unsorted elements were shifted right, thereby maintaining their original order, then this modified version of the selection sort algorithm would be stable, however shifting array elements is an O(n) operation, and this modified selection sort algorithm would be O(n**3) instead of the superior O(n squared) scaling efficiency relative to input size of the original selection sort algorithm.

#### Is insertion sort stable? Why or why not?
Let's see by walking through.
original array: [2(a),3(a),3(b),2(b),2(c)]
// before first iteration 
[2(a)][3(a),3(b),2(b),2(c)]
// 1st iter
[2(a), 3(a)][3(b),2(b),2(c)]
// 2nd iter
[2(a), 3(a), 3(b)][2(b),2(c)]
// 3rd iter
[2(a), 2(b), 3(a), 3(b)][2(c)]
// 4th iter
[2(a), 2(b), 2(c), 3(a), 3(b)]

It appears that insertion sort is also a stable sorting algorithm, because elements are added to the sorted part of the array one at a time in the order in which they were found in the original array, and when a second duplicate item is added to the sorted part of the array it is compared to preceeding items and the index representing its position in the sorted part of the array is updated to match that of the last item it was smaller than until it is compared to item it is not smaller than, for example the first duplicate, with which it will not be swapped and instead that will trigger the iteration back through the sorted part to stop and the array to be shifted right to allow space for the item to be placed in its correct position in the sorted part of the array, after duplicates of its own value.

In conclusion, vanilla selection sort is an unstable sorting algorithm whereas insertion sort is a stable sorting algorithm, i.e., the order of duplicate elements in the original array is preserved in an array sorted with insertion sort but not preserved in an array sorted with selection sort.

